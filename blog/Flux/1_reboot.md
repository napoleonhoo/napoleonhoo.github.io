# 第一章 重启

flux不是面向PPT的，不是面向汇报的，更不是凭空臆造出来的。是为了**解决实际问题，解决用户痛点**而提出来的一个训练框架。要想了解flux，必须了解它解决了什么问题，也就必须了解我厂机器学习的现状。在我厂，或者说feed内，目前主流的框架是abacus和paddle。

## 1. 简史：从abacus到paddle

### abacus

abacus是我厂开发的较早时期的模型训练框架，支持大规模离散参数模型训练，它的JOIN+UPDATE双阶段方法在当时属于业内领先。

从代码结构上来讲，它主要是C++写就的。通过配置来控制模型路径，数据（一般是feasign）路径，何时保存checkpoint、xbox，梯度下降的算法等等。策略同学的主要开发点在join.yaml和update.yaml这两个配置文件。通过这两个配置文件，调用abacus里面实现好的各种layer，如fc、entrywise_product、normalization、loss等。

从分布式架构上来讲，它是一个主从或者说master-slave结构的。最先起来的节点作为0号节点，负责总体流程的控制。它使用MPI通信，部署在每个节点上的代码实际上是一样的。每个节点同时作为worker（训练用）、server（参数服务器），并非是完全对等的节点，它read不同的数据，load模型参数不同的部分（sparse的一部分，dense的全部）。

从使用的角度上来讲，自定义能力强，开发新的layer或功能是比较方便的。但是，由于其很多流程上的东西都是由框架定义的，缺少一定的**灵活性**。layer毕竟有限，对不太熟悉C++的同学不太友好，对模型的开发相对受限。在这个背景上来讲，paddle就应运而生了。

### paddle

paddle作为我厂官方层面上的又一最新力作，厂内被广泛使用，在厂外也有一些影响。它优秀的性能足以支撑更大规模的模型；它的设计，又足以支撑更复杂的模型结构。

从代码结构上来讲，它主体的部分仍由C++完成，但面向用户的接口已经变成了Python。虽然不一定所有同学都会用C++，但大部分同学都会用Python。它提供了一些比abacus中更为底层的一些接口，可以由用户编写一些基础的流程控制。它不仅支持abacus也支持的如fc、normalization等，也提供了比如加减乘除这种更精细化的operator。

从分布式架构上来讲，和abacus并没有太大的区别。同样地，它的worker、server也是在一个节点上的，最先起来的节点是0号节点，每个节点read不同的数据，load模型参数不同的部分（sparse、dense的一部分）。

从使用的角度上来讲，它operator足够精细，满足大部分的模型结构需求。但operator的二次开发相对abacus要困难一些。它的依赖更加复杂，深层的debug要建立在对框架有一定的熟练程度上。

### 历史课小结

通过以上的讲述，我们可以看到abacus与paddle存在的一些共同的特性：

- 不具备单点容错能力。
  - worker不具备单点容错能力，因为它的底层是MPI、Gloo，一次的通信失败可能导致一个节点的退出。
  - server不具备单点容错能力，server存储了不同的参数数据，没有足够的冗余，任何一个节点失败都不能允许。
  - 任何一个节点因为其他原因的fail，如OOM等，都会导致整个任务的失败，然后整个任务需要重提，重跑。
- 资源使用效率不足。worker和server在同一个节点上就意味着共享CPU、内存。然而，在现实场景下：
  - 大多数的worker需要更多的CPU用于训练，大多数的server需要更多的内存用于存储。
  - 并且，节点不是越多越好，更多的节点带来了更多的通信，这对网络也提出了更高的要求。

备注：鉴于作者的认知水平，本文暂不讨论GPU相关内容。

## 2. feed出了个flux

我们组内常听到用户同学这样说：

- “我的任务fail了，麻烦帮忙看下？/乖”
- “大佬，我的任务排了3个小时的队还是排不上，帮忙找一个稍微空点儿的队列呗！/抱拳”
- “天哪，我这个模型的调研任务慢死了，需要48小时才能跑24个delta。/笑哭。一小时一个的delta。。。”
- “……”

时代在发展，社会在进步，模型训练进入了**新时代**，今时今日的框架已经不能满足大家的需求了。越来越大的模型，越来越多的任务，越来越少的资源，在昭示着我们业务蓬勃发展、策略同学热情探索的时候，也为我们的训练框架提出了新的挑战与要求。简单来讲，主要可以分为以下几点：

1. 任务稳定性太差。
2. 任务效率不行（运行速度太慢）。
3. 任务资源不足，或者说任务使用的资源太多了。

flux的出现就是为了解决这些问题。但是，必须要说明的一点是，flux不是推到重来，更不是把两者的代码放在一起就成了一个新框架。它与abacus、paddle是一脉相承又与时俱进的。

### 一脉相承

flux提供了abaucs、paddle的插件，它的正向、反向传播就是使用的原生abacus、paddle。从外表上看，flux和它的前辈们没有太大的差别，都是sparse、dense，都是读feasign，都是写xbox。（当然更深层次还是有很大区别的。）这也使得大部分的abacus、paddle用户都可以无痛迁移flux。

### 与时俱进

flux通过以下几个方法，解决了前文提到的模型训练新时代面临的问题，并且还做了更多。简单来讲：

- 高可用，具备单点容错能力，支持训练不中断的builtin-failover能力。

- 可弹性伸缩，Worker无状态&可运行期动态扩缩。

更通俗和具体的来讲：

- worker、server角色分离，带来了对资源的更加细微可控，更省资源，更有效率。
- 节点可迁移，遇到问题不用慌，迁移一下，不需重启。
- 性能极致优化，快些，再快些。

### 超出预期的

flux还有一些超出预期的能力，在这里简述一下，在本篇文章中不会过多涉及：

- 多任务平台，不止MPI。PaaS、K8S等。
- 异构混合训练加速（HIPO），实现CPU+GPU的模型训练加速。（这里不会过多涉及，下面谈的flux专指CPU上的。）

### 效果

目前为止，flux落地9个产品线，累计节省249223 CPU、85541G Mem，天级训练成本降低14206.4元，资源节省比例60+%。

## 3. 正文开始：flux学习路径

先简单谈一下flux的模块组成与简介：

- coordinator：flux的核心角色、调度者、master-slave模式下的master。主要代码库：coordinator。
- worker：主要负责训练部分，主要代码库：
  - flux-engine：训练部分主框架，train、pull、push
  - flux-dnn-plugin：支持abacus、paddle的插件。
  - flux-data-reader：读feasign。
  - flux-models：模型的结构。
- server：参数服务器，主要代码库：flux-ps。

学习代码，就要把握住它的核心，我认为的核心是：

- coordinator：通信
- flus-ps：存储
- flux-engine：性能

当然，并不是说只有flux-engine才关注性能，coordinator、flus-ps就不关注了，不是这样的。这里只是把握住了重点。

必须要说明的是，学习flux需要对模型训练有基本的了解，如果没有足够了解的话，可以先看下附录一、二。

下面，我们开始吧！
